{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-17T12:57:56.014693Z","iopub.status.busy":"2023-07-17T12:57:56.014179Z","iopub.status.idle":"2023-07-17T12:57:56.032897Z","shell.execute_reply":"2023-07-17T12:57:56.031657Z","shell.execute_reply.started":"2023-07-17T12:57:56.014646Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv\n","/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv\n","/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.200d.txt\n","/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.50d.txt\n","/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt\n","/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\n","/kaggle/input/tweet-sentiment-extraction/train.csv\n","/kaggle/input/tweet-sentiment-extraction/test.csv\n","/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n"]}],"source":["import numpy as np\n","import pandas as pd \n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:56.037559Z","iopub.status.busy":"2023-07-17T12:57:56.036485Z","iopub.status.idle":"2023-07-17T12:57:56.051325Z","shell.execute_reply":"2023-07-17T12:57:56.049942Z","shell.execute_reply.started":"2023-07-17T12:57:56.037515Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","from tqdm import tqdm\n","from sklearn.svm import SVC\n","from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","stop_words = stopwords.words('english')\n","import re\n","import string\n","from nltk.corpus import stopwords \n","from collections import Counter\n","import string\n","import re\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn import svm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:56.057432Z","iopub.status.busy":"2023-07-17T12:57:56.055275Z","iopub.status.idle":"2023-07-17T12:57:56.392528Z","shell.execute_reply":"2023-07-17T12:57:56.391359Z","shell.execute_reply.started":"2023-07-17T12:57:56.057389Z"},"trusted":true},"outputs":[],"source":["test_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv', header=None)\n","train_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\n","test_df.reset_index(drop=True,inplace=True)\n","train_df.reset_index(drop=True,inplace=True)\n","df = pd.concat([train_df,test_df], axis=0)\n","df.drop([0], axis=1, inplace=True)\n","df.columns = ['platform','sentiment','text']\n","df.drop(['platform'], axis=1, inplace=True)\n","df.sentiment = df.sentiment.map({\"Neutral\":0, \"Irrelevant\":0 ,\"Positive\":1,\"Negative\":2})\n","df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:56.398054Z","iopub.status.busy":"2023-07-17T12:57:56.396443Z","iopub.status.idle":"2023-07-17T12:57:56.415372Z","shell.execute_reply":"2023-07-17T12:57:56.414068Z","shell.execute_reply.started":"2023-07-17T12:57:56.398008Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>im getting on borderlands and i will murder yo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>I am coming to the borders and I will kill you...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>im getting on borderlands and i will kill you ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>im coming on borderlands and i will murder you...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>im getting on borderlands 2 and i will murder ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>0</td>\n","      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>0</td>\n","      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>1</td>\n","      <td>Today sucked so it’s time to drink wine n play...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>1</td>\n","      <td>Bought a fraction of Microsoft today. Small wins.</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>0</td>\n","      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>74996 rows × 2 columns</p>\n","</div>"],"text/plain":["     sentiment                                               text\n","0            1  im getting on borderlands and i will murder yo...\n","1            1  I am coming to the borders and I will kill you...\n","2            1  im getting on borderlands and i will kill you ...\n","3            1  im coming on borderlands and i will murder you...\n","4            1  im getting on borderlands 2 and i will murder ...\n","..         ...                                                ...\n","995          0  ⭐️ Toronto is the arts and culture capital of ...\n","996          0  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...\n","997          1  Today sucked so it’s time to drink wine n play...\n","998          1  Bought a fraction of Microsoft today. Small wins.\n","999          0  Johnson & Johnson to stop selling talc baby po...\n","\n","[74996 rows x 2 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:56.418623Z","iopub.status.busy":"2023-07-17T12:57:56.416873Z","iopub.status.idle":"2023-07-17T12:57:58.282600Z","shell.execute_reply":"2023-07-17T12:57:58.281391Z","shell.execute_reply.started":"2023-07-17T12:57:56.418432Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>im getting borderlands murder</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>coming borders kill</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>im getting borderlands kill</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>im coming borderlands murder</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>im getting borderlands 2 murder</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment                             text\n","0          1    im getting borderlands murder\n","1          1              coming borders kill\n","2          1      im getting borderlands kill\n","3          1     im coming borderlands murder\n","4          1  im getting borderlands 2 murder"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["stop_words = set(stopwords.words('english'))\n","def data_preprocessing(text):\n","    text = text.lower()\n","    text = re.sub('<.*?>', '', text) \n","    text = ''.join([c for c in text if c not in string.punctuation])\n","    text = [word for word in text.split() if word not in stop_words]\n","    text = ' '.join(text)\n","    return text\n","\n","df['text'] = df['text'].astype(str).apply(data_preprocessing)\n","\n","df.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:58.284794Z","iopub.status.busy":"2023-07-17T12:57:58.284297Z","iopub.status.idle":"2023-07-17T12:57:58.302868Z","shell.execute_reply":"2023-07-17T12:57:58.301826Z","shell.execute_reply.started":"2023-07-17T12:57:58.284753Z"},"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(df.text, df.sentiment, test_size=0.2, random_state=1)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:58.305086Z","iopub.status.busy":"2023-07-17T12:57:58.304434Z","iopub.status.idle":"2023-07-17T12:57:58.311731Z","shell.execute_reply":"2023-07-17T12:57:58.310554Z","shell.execute_reply.started":"2023-07-17T12:57:58.305043Z"},"trusted":true},"outputs":[],"source":["y_train = y_train.astype('int')\n","y_test= y_test.astype('int')"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:58.317041Z","iopub.status.busy":"2023-07-17T12:57:58.316701Z","iopub.status.idle":"2023-07-17T12:57:58.323156Z","shell.execute_reply":"2023-07-17T12:57:58.321930Z","shell.execute_reply.started":"2023-07-17T12:57:58.317010Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(59996,)\n","(15000,)\n"]}],"source":["print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## TF-IDF"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:57:58.325470Z","iopub.status.busy":"2023-07-17T12:57:58.325059Z","iopub.status.idle":"2023-07-17T12:58:07.112012Z","shell.execute_reply":"2023-07-17T12:58:07.110758Z","shell.execute_reply.started":"2023-07-17T12:57:58.325430Z"},"trusted":true},"outputs":[],"source":["tfv = TfidfVectorizer(min_df=3,  max_features=None, \n","            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n","            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1)\n","\n","tfv.fit(list(X_train) + list(X_test))\n","xtrain_tfv =  tfv.transform(X_train) \n","xvalid_tfv = tfv.transform(X_test)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Count Vectorizer"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:58:07.114276Z","iopub.status.busy":"2023-07-17T12:58:07.113593Z","iopub.status.idle":"2023-07-17T12:58:17.225431Z","shell.execute_reply":"2023-07-17T12:58:17.224193Z","shell.execute_reply.started":"2023-07-17T12:58:07.114231Z"},"trusted":true},"outputs":[],"source":["ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n","            ngram_range=(1, 3))\n","\n","\n","ctv.fit(list(X_train) + list(X_test))\n","xtrain_ctv =  ctv.transform(X_train) \n","xvalid_ctv = ctv.transform(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["## GloVe"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:58:17.227744Z","iopub.status.busy":"2023-07-17T12:58:17.227100Z","iopub.status.idle":"2023-07-17T12:58:17.233497Z","shell.execute_reply":"2023-07-17T12:58:17.232102Z","shell.execute_reply.started":"2023-07-17T12:58:17.227699Z"},"trusted":true},"outputs":[],"source":["glove_path = '/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.200d.txt'"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:58:17.235986Z","iopub.status.busy":"2023-07-17T12:58:17.235605Z","iopub.status.idle":"2023-07-17T12:58:17.243926Z","shell.execute_reply":"2023-07-17T12:58:17.242859Z","shell.execute_reply.started":"2023-07-17T12:58:17.235945Z"},"trusted":true},"outputs":[],"source":["def load_word_embeddings(file=glove_path):\n","    embeddings={}\n","    with open(file,'r') as infile:\n","        for line in infile:\n","            values=line.split()\n","            embeddings[values[0]]=np.asarray(values[1:],dtype='float32')\n","    return embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:58:17.246182Z","iopub.status.busy":"2023-07-17T12:58:17.245378Z"},"trusted":true},"outputs":[],"source":["glove_embeddings = load_word_embeddings()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def sentence_features_v2(s, embeddings=glove_embeddings,emb_size=200):\n","    # ignore stop words\n","    words=s\n","    words=[w for w in words if w.isalpha() and w in embeddings]\n","    if len(words)==0:\n","        return np.hstack([np.zeros(emb_size)])\n","    M=np.array([embeddings[w] for w in words])\n","    return M.mean(axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_glove = np.array([sentence_features_v2(x) for x in X_train])\n","test_glove = np.array([sentence_features_v2(x) for x in X_test])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_glove.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["clf = LogisticRegression(random_state=0, multi_class='multinomial')\n","clf.fit(xtrain_tfv, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_pred = clf.predict(xvalid_tfv)\n","print(\"The accurary of logistic regression with tf-idf embedding is\",accuracy_score(list(y_test), val_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["clf = LogisticRegression(random_state=0, multi_class='multinomial')\n","clf.fit(xtrain_ctv, y_train)\n","val_pred = clf.predict(xvalid_ctv)\n","print(\"The accurary of logistic regression with count-vectorizer embedding is\",accuracy_score(list(y_test), val_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predict=pd.DataFrame(val_pred)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predict_file=predict.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-04-07T12:53:19.227417Z","iopub.status.busy":"2023-04-07T12:53:19.226751Z","iopub.status.idle":"2023-04-07T12:53:19.301822Z","shell.execute_reply":"2023-04-07T12:53:19.299929Z","shell.execute_reply.started":"2023-04-07T12:53:19.22733Z"}},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
